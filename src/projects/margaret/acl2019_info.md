## Quantifying Gender Bias on Twitter

Modern models for common NLP tasks have recently been scrutinized for racial and gender biases, rooting from inherent bias in their training text. These biases are often sub-optimal and recent work poses methods to rectify them; however, these biases may shed light on actual racial or gender gaps in the culture(s) that produced the training text, thereby helping us understand cultural context through big data. This research presents an approach for quantifying gender bias in word embeddings, and then using them to characterize statistical gender gaps in education, politics, economics, and health. This research presents an approach for quantifying gender bias on Twitter data and using them to characterize statistical gender gaps in education, politics, economics, and health. This paper was published in the GeBNLP workshop in the ACL conference.

See paper [here](https://www.aclweb.org/anthology/W19-3803/)
